#InvestigaÃ§Ã£o de Anomalias CardÃ­acas em Datasets de Eletrocardiogramas> **Projeto de ConclusÃ£o de Curso (TCC)** > **Curso:** CiÃªncia da ComputaÃ§Ã£o - PUCPR
> **Autores:** Henrique L. Richa, Renan B. Biavati, VitÃ³ria Izabel M. Pinto
> <img width="544" height="460" alt="image" src="https://github.com/user-attachments/assets/688f2be7-31fd-4da9-923e-8a9585ad7505" />


##ğŸ“‹ Sobre o Projeto Este projeto explora a aplicaÃ§Ã£o de tÃ©cnicas de **Aprendizado de MÃ¡quina (Machine Learning)** na anÃ¡lise de eletrocardiogramas (ECG), com o objetivo de automatizar e aprimorar a detecÃ§Ã£o de anomalias cardÃ­acas.

Diante da complexidade dos dados de ECG, o estudo compara diversos algoritmos de aprendizado supervisionado para identificar padrÃµes no **MIT-BIH Arrhythmia Database**, maximizando mÃ©tricas crÃ­ticas como acurÃ¡cia e especificidade.

##ğŸ¯ Objetivos* Comparar a eficÃ¡cia de diferentes modelos de ML na classificaÃ§Ã£o de batimentos cardÃ­acos.
* Otimizar hiperparÃ¢metros utilizando **GridSearch** para refinar os resultados.


* Implementar tÃ©cnicas avanÃ§adas de **Ensemble (Stacking)** para superar o desempenho de modelos isolados.

##ğŸ—ƒï¸ Base de DadosO projeto utiliza o **MIT-BIH Arrhythmia Database** (https://www.kaggle.com/datasets/shayanfazeli/heartbeat), um padrÃ£o-ouro para pesquisas de arritmia.

* 
**Classes Analisadas:** O dataset possui 5 classes principais de batimentos (Normal, Supraventricular, Ventricular, FusÃ£o, InclassificÃ¡vel).


* 
*Nota:* O *PTB Diagnostic ECG Database* foi analisado, mas excluÃ­do do escopo final devido Ã  incompatibilidade de classes para junÃ§Ã£o direta.



##ğŸš€ Tecnologias e BibliotecasO projeto foi desenvolvido em **Python** utilizando **Jupyter Notebooks**.

* **ManipulaÃ§Ã£o de Dados:** `pandas`, `numpy`
* **VisualizaÃ§Ã£o:** `matplotlib`, `seaborn`
* **Machine Learning:** `scikit-learn`
* **Modelos AvanÃ§ados:** `xgboost`
* **Ensemble:** `vecstack`
* **SerializaÃ§Ã£o:** `joblib`

##ğŸ§  Modelos ImplementadosForam desenvolvidos e avaliados 7 modelos individuais e 1 estratÃ©gia de Stacking:

1. 
**KNN (K-Nearest Neighbors)** 


2. 
**SVM (Support Vector Machine)** 


3. 
**Random Forest** 


4. 
**MLP (Multilayer Perceptron)** 


5. 
**AdaBoost** 


6. 
**Gradient Boosting** 


7. 
**XGBoost** 


8. 
**Stacking (Ensemble)**: CombinaÃ§Ã£o das previsÃµes dos modelos acima.



##ğŸ“‚ Estrutura do RepositÃ³rioOs arquivos estÃ£o organizados conforme a etapa de experimentaÃ§Ã£o:

| Arquivo | DescriÃ§Ã£o |
| --- | --- |
| `experimentacao_knn.ipynb` | Treinamento e otimizaÃ§Ã£o do KNN. |
| `experimentacao_svm.ipynb` | Treinamento e otimizaÃ§Ã£o do SVM. |
| `experimentacao_randomforest.ipynb` | Treinamento e otimizaÃ§Ã£o do Random Forest. |
| `experiementacao_mlp.ipynb` | Treinamento e otimizaÃ§Ã£o da Rede Neural MLP. |
| `experiementacao_adaboost.ipynb` | Treinamento e otimizaÃ§Ã£o do AdaBoost. |
| `experimentacao_gradientboost.ipynb` | Treinamento e otimizaÃ§Ã£o do Gradient Boosting. |
| `experimentacao_xgboost.ipynb` | Treinamento e otimizaÃ§Ã£o do XGBoost. |
| `experimentacao_stacking4.ipynb` | **Modelo Final:** EstratÃ©gia de Stacking (Meta-modelo XGBoost) utilizando os melhores classificadores base. |
| `Artigo CientÃ­fico.pdf` | DocumentaÃ§Ã£o teÃ³rica completa e anÃ¡lise detalhada dos resultados. |

##ğŸ“Š Resultados ChaveOs modelos passaram por rigorosa otimizaÃ§Ã£o de hiperparÃ¢metros. Abaixo, os destaques dos resultados otimizados (MÃ©dia Ponderada):

| Modelo | AcurÃ¡cia | F1-Score | Especificidade |
| --- | --- | --- | --- |
| **XGBoost** | **98.0%** | **98.0%** | **98.44%** |
| SVC | 98.0% | 98.0% | 98.0% |
| KNN | 97.7% | 97.6% | 97.6% |
| MLP Classifier | 97.1% | 97.0% | 97.8% |
| GradientBoost | 97.0% | 97.0% | 96.8% |
| Random Forest | 97.0% | 96.5% | 96.8% |
| AdaBoost | 89.0% | 87.0% | 88.8% |

> 
> **Destaque:** O **XGBoost** apresentou o melhor desempenho individual. A estratÃ©gia de **Stacking (Experimento 4)**, utilizando o melhor modelo como meta-modelo, demonstrou superioridade sobre estratÃ©gias que utilizavam modelos mais fracos como decisores.
> 
> 

##âš™ï¸ Como Executar1. **Instale as dependÃªncias:**
```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost vecstack tabulate joblib

```


2. **Dataset:** Certifique-se de que os arquivos `mitbih_train.csv` e `mitbih_test.csv` estejam no mesmo diretÃ³rio dos notebooks.
3. **ExecuÃ§Ã£o:**
* Execute os notebooks `experimentacao_<modelo>.ipynb` individualmente para ver o treinamento e a geraÃ§Ã£o dos arquivos `.joblib`.
* Execute `experimentacao_stacking4.ipynb` para rodar o ensemble final.



---

###ğŸ“ CitaÃ§Ã£o
Se utilizar este trabalho ou parte dele, favor citar:

> Richa, H. L.; Biavati, R. B.; Pinto, V. I. M. (2024). *InvestigaÃ§Ã£o de Anomalias CardÃ­acas em Datasets de Eletrocardiogramas*. PontifÃ­cia Universidade CatÃ³lica do ParanÃ¡ (PUCPR). 
> 
> 

---
