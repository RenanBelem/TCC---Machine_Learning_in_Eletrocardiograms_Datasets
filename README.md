# Investiga√ß√£o de Anomalias Card√≠acas em Datasets de Eletrocardiogramas
> **Projeto de Conclus√£o de Curso (TCC)** > **Curso:** Ci√™ncia da Computa√ß√£o - PUCPR
> 
> **Autores:** Henrique L. Richa, Renan B. Biavati, Vit√≥ria Izabel M. Pinto

> <img width="544" height="460" alt="image" src="https://github.com/user-attachments/assets/688f2be7-31fd-4da9-923e-8a9585ad7505" />

## üìã Sobre o Projeto
Este projeto explora a aplica√ß√£o de t√©cnicas de **Aprendizado de M√°quina (Machine Learning)** na an√°lise de eletrocardiogramas (ECG), com o objetivo de automatizar e aprimorar a detec√ß√£o de anomalias card√≠acas.

Diante da complexidade dos dados de ECG, o estudo compara diversos algoritmos de aprendizado supervisionado para identificar padr√µes no **MIT-BIH Arrhythmia Database**, maximizando m√©tricas cr√≠ticas como acur√°cia e especificidade.

## üéØ Objetivos
* Comparar a efic√°cia de diferentes modelos de ML na classifica√ß√£o de batimentos card√≠acos.
* Otimizar hiperpar√¢metros utilizando **GridSearch** para refinar os resultados.


* Implementar t√©cnicas avan√ßadas de **Ensemble (Stacking)** para superar o desempenho de modelos isolados.

## üóÉÔ∏è Base de Dados
O projeto utiliza o **MIT-BIH Arrhythmia Database**, um padr√£o-ouro para pesquisas de arritmia.
(https://www.kaggle.com/datasets/shayanfazeli/heartbeat)

* **Classes Analisadas:** O dataset possui 5 classes principais de batimentos (Normal, Supraventricular, Ventricular, Fus√£o, Inclassific√°vel).


* *Nota:* O *PTB Diagnostic ECG Database* foi analisado, mas exclu√≠do do escopo final devido √† incompatibilidade de classes para jun√ß√£o direta.



## üöÄ Tecnologias e Bibliotecas
O projeto foi desenvolvido em **Python** utilizando **Jupyter Notebooks**.

* **Manipula√ß√£o de Dados:** `pandas`, `numpy`
* **Visualiza√ß√£o:** `matplotlib`, `seaborn`
* **Machine Learning:** `scikit-learn`
* **Modelos Avan√ßados:** `xgboost`
* **Ensemble:** `vecstack`
* **Serializa√ß√£o:** `joblib`

## üß† Modelos Implementados
Foram desenvolvidos e avaliados 7 modelos individuais e 1 estrat√©gia de Stacking:

1. **KNN (K-Nearest Neighbors)** 

2. **SVM (Support Vector Machine)** 

3. **Random Forest** 

4. **MLP (Multilayer Perceptron)** 

5. **AdaBoost** 

6. **Gradient Boosting** 

7. **XGBoost** 

8. **Stacking (Ensemble)**: Combina√ß√£o das previs√µes dos modelos acima.



## üìÇ Estrutura do Reposit√≥rio
Os arquivos est√£o organizados conforme a etapa de experimenta√ß√£o:

| Arquivo | Descri√ß√£o |
| --- | --- |
| `experimentacao_knn.ipynb` | Treinamento e otimiza√ß√£o do KNN. |
| `experimentacao_svm.ipynb` | Treinamento e otimiza√ß√£o do SVM. |
| `experimentacao_randomforest.ipynb` | Treinamento e otimiza√ß√£o do Random Forest. |
| `experiementacao_mlp.ipynb` | Treinamento e otimiza√ß√£o da Rede Neural MLP. |
| `experiementacao_adaboost.ipynb` | Treinamento e otimiza√ß√£o do AdaBoost. |
| `experimentacao_gradientboost.ipynb` | Treinamento e otimiza√ß√£o do Gradient Boosting. |
| `experimentacao_xgboost.ipynb` | Treinamento e otimiza√ß√£o do XGBoost. |
| `experimentacao_stacking4.ipynb` | **Modelo Final:** Estrat√©gia de Stacking (Meta-modelo XGBoost) utilizando os melhores classificadores base. |
| `Artigo Cient√≠fico.pdf` | Documenta√ß√£o te√≥rica completa e an√°lise detalhada dos resultados. |

## üìä Resultados Chave
Os modelos passaram por rigorosa otimiza√ß√£o de hiperpar√¢metros. Abaixo, os destaques dos resultados otimizados (M√©dia Ponderada):

| Modelo | Acur√°cia | F1-Score | Especificidade |
| --- | --- | --- | --- |
| **XGBoost** | **98.0%** | **98.0%** | **98.44%** |
| SVC | 98.0% | 98.0% | 98.0% |
| KNN | 97.7% | 97.6% | 97.6% |
| MLP Classifier | 97.1% | 97.0% | 97.8% |
| GradientBoost | 97.0% | 97.0% | 96.8% |
| Random Forest | 97.0% | 96.5% | 96.8% |
| AdaBoost | 89.0% | 87.0% | 88.8% |

> 
> **Destaque:** O **XGBoost** apresentou o melhor desempenho individual. A estrat√©gia de **Stacking (Experimento 4)**, utilizando o melhor modelo como meta-modelo, demonstrou superioridade sobre estrat√©gias que utilizavam modelos mais fracos como decisores.
> 
> 

## ‚öôÔ∏è Como Executar
1. **Instale as depend√™ncias:**
```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost vecstack tabulate joblib

```

2. **Dataset:** Certifique-se de que os arquivos `mitbih_train.csv` e `mitbih_test.csv` estejam no mesmo diret√≥rio dos notebooks.
3. **Execu√ß√£o:**
* Execute os notebooks `experimentacao_<modelo>.ipynb` individualmente para ver o treinamento e a gera√ß√£o dos arquivos `.joblib`.
* Execute `experimentacao_stacking4.ipynb` para rodar o ensemble final.



---

### üìù Cita√ß√£o
Se utilizar este trabalho ou parte dele, favor citar:

> Richa, H. L.; Biavati, R. B.; Pinto, V. I. M. (2024). *Investiga√ß√£o de Anomalias Card√≠acas em Datasets de Eletrocardiogramas*. Pontif√≠cia Universidade Cat√≥lica do Paran√° (PUCPR). 

---
